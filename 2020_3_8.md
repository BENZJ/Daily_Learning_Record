# 今日计划
1 读论文"Not All Adversarial Examples Require a Complex Defense: Identifying Over-optimized Adversarial Examples with IQR-based Logit Thresholding"

# 论文记录
## Not All Adversarial Examples Require a Complex Defense: Identifying Over-optimized Adversarial Examples with IQR-based Logit Thresholding
## 对攻击方法尽尽心了概述
### 基本的迭代方法 Basic Iterative Method
$$x_{n+1}= x_n - \alpha sign\nabla_xJ(g(\theta,x_n)_c)$$
$$x_{n+1}= Clip_x\in (x_n - \alpha sign\nabla_xJ(g(\theta,x_n)_c))$$
可以对迭代的方法进行总结描述，主要包括I-FGS方法就是把FGSM改进为迭代的方法。
### 对C&W算法进行了介绍
这个论文之后要看，“Towards evaluating the robustness of neural networks,” CoRR, vol. abs/1608.04644, 2016.
###

